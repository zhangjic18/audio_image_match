<h1 style="text-align:center">基于音频和图像序列的物体撞击匹配</h1>

[toc]

## 1 任务说明

### 1.1 音频分类

​		不同物体的物理性质不同，因此撞击的音频也具有不同的特点。任务一要求仅利用物体撞击的四通道音频信息对物体的种类进行分类，要求对每个音频文件估计分类物体的编号。

### 1.2 完全匹配

​		撞击音频不仅包含有关物体种类的信息，还包含物体撞击方向、位置等信息。考虑若干对匹配的音频和视频，将对应关系打乱之后，任务二要求同学们通过分析音频和视频的特征来恢复二者的对应关系。任务二中待匹配的音频和视频数量相同，且音频和视频之间存在一一对应关系。关于匹配问题，可以参考匈牙利算法、KM算法等经典算法。

### 1.3 不完全匹配

​		任务三与任务二的目标相同，同样是对音频和视频进行匹配。区别在于任务三不保证待匹配音频和视频一一对应：存在不确定数量的音频没有与之对应的视频，也存在不确定数量的视频没有与之对应的音频。

## 2 方法简介

### 2.0 数据预处理

1. 对于音频，将每个`audio_data.pkl`处理为4\*64\*256的`melspectrogram feature`和4\*64\*256的`mfcc feature`，将二者分别归一化后再`cat`在一起，最终得到一个8\*64\*256的`tensor`
2. 对于图像，首先对RGB图像进行裁剪，左右各裁去100个像素，上下各裁去20个像素，得到的图像尺寸为440*440，再利用掩膜将RGB图像的背景置为0，然后将序列`cat`在一起，得到60\*440\*440的`tensor`，最后，对`tensor`进行归一化
3. 构建音频分类的训练集、验证集、测试集
4. 构建图像分类的训练集、验证集、测试集

### 2.1 音频分类

​		将每个`audio_data.pkl`处理为4\*64\*256的`melspectrogram feature`和4\*64\*256的`mfcc feature`，将二者分别归一化后再`cat`在一起，最终得到一个8\*64\*256的`tensor`，再利用`resnet18`进行分类。

### 2.2 完全匹配

1. 利用`resnet18__to_audio_classify.pth`提取音频特征
2. 利用`resnet18__to_image_classify.pth`提取图像序列特征
3. 将提取的特征`flatten`，再`cat`为一个一维`tensor`，然后送入2层的`mlp`
3. 总共20次`episode`，每次`episode`中，从原始数据集中构建数量均衡的匹配网络训练数据集，训练二分类匹配网络
3. 模型训练结束后，再采用匈牙利算法做完全匹配

### 2.3 不完全匹配

​		基本思路同完全匹配，因为匈牙利算法可以解决“工人”与“任务”数量不一致的问题，即`similarity`矩阵不是方阵的问题。

## 3 项目结构


* `src`：源代码
  * `dataset`：包含各种构建数据集的`.py`文件
  * `model`：包含各种`.py`模型文件
  * `preprocess.py`：预处理
  * `image_classify.py`：图像序列分类
  * `audio_classify.py`：音频分类
  * `match_net_train.py`：匹配网络训练
  * `task_1.py`：完成任务1
  * `task_2.py`：完成任务2
  * `task_3.py`：完成任务3
  * `test.py`：完成助教要求的`test`函数
  * `utils.py`：工具类：`AverageMeter`
* `data`：
  * `original_data`
  * `processed_data`
  * `image`
  * `audio`
* `checkpoints`
* `doc`
* `README.md`
* `requirements.txt`

## 4 实验效果

1. 音频准确率：86%
2. 图像分类准确率：99%
3. 完全匹配正确率：